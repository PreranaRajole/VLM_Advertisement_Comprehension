# Visual-Linguistic-Advertisement-Analysis
Investigate the differences between human and AI interpretation of commercial messaging

VLM Advertisement Comprehension Analysis

Evaluating how Visual Language Models understand and generate advertisement content compared to humans

Project Overview
This research project evaluates the advertisement comprehension capabilities of five Visual Language Models (VLMs) compared to human performance. We focus on two key aspects:

Comparative Text Generation: Analyzing the quality and effectiveness of advertisement text generated by VLMs versus human copywriters
Image-Text Alignment: Testing VLMs' ability to select the most appropriate image from multiple options when given advertisement text

Dataset
Our dataset consists of:

Original advertisements with both text and images
Text-extracted versions (using OCR)
Text-free images (created using Microsoft's image eraser)
Human-annotated selling points for each advertisement

Methodology
Data Processing Pipeline

Advertisement collection across diverse categories
Text extraction using OCR techniques
Text removal from images using Microsoft's image eraser
Manual annotation of key selling points by human annotators

Evaluation Tasks

Text Generation: VLMs generate advertisement copy for text-free images
Image Selection: VLMs select the most appropriate image from 5 candidates when given advertisement text

Model Evaluation
We evaluate 5 different Visual Language Models (details to be added):
[LLaVA-NeXT]{https://huggingface.co/docs/transformers/en/model_doc/llava_next} 

