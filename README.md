# Visual-Linguistic-Advertisement-Analysis

## Investigate the differences between human and AI interpretation of commercial messaging

This project evaluates the advertisement comprehension capabilities of five Visual Language Models (VLMs) compared to human performance. We focus on two key aspects:

* Comparative Text Generation: Analyzing the quality and effectiveness of advertisement text generated by VLMs versus human copywriters
* Image-Text Alignment: Testing VLMs' ability to select the most appropriate image from multiple options when given advertisement text

### Dataset
Our dataset consists of:

* Original advertisements with both text and images
* Text-extracted versions
* Text-free images
* Human-annotated selling points for each advertisement

### Methodology
Data Processing Pipeline

1. Advertisement collection across 11 categories
2. Text extraction using OCR techniques
3. Text removal from images using Microsoft's image eraser
4. Manual annotation of key selling points by human annotators


Model Evaluation
We evaluate 5 different Visual Language Models:

[LLaVA-NeXT](https://huggingface.co/docs/transformers/en/model_doc/llava_next)
[LLaVA-OneVision](https://huggingface.co/docs/transformers/en/model_doc/llava_onevision)
[Pixtral](https://huggingface.co/docs/transformers/en/model_doc/pixtral)
[Qwen2.5-VL](https://huggingface.co/docs/transformers/en/model_doc/qwen2_5_vl)
[VisualBERT](https://huggingface.co/docs/transformers/en/model_doc/visual_bert)

